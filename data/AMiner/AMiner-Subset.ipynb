{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5259858/5259858 [04:49<00:00, 18140.34it/s] \n"
     ]
    }
   ],
   "source": [
    "is_xl_data = False\n",
    "\n",
    "selected_papers = []\n",
    "\n",
    "keywords = {\n",
    "    \"deep learning\",\n",
    "    \"artificial intelligence\",\n",
    "    \"machine learning\",\n",
    "    \"computer vision\",\n",
    "    \"natural language processing\",\n",
    "    \"reinforcement learning\",\n",
    "    \"information retrieval\",\n",
    "    \"information extraction\",\n",
    "    \"unsupervised learning\",\n",
    "    \"speech recognition\",\n",
    "    \"neural networks\",\n",
    "    \"supervised learning\",\n",
    "    \"convolutional neural networks\",\n",
    "    \"recurrent neural networks\",\n",
    "    \"data mining\",\n",
    "    \"graph neural networks\",\n",
    "    \"dimensionality reduction\",\n",
    "    \"explainable ai\",\n",
    "    \"adversarial learning\",\n",
    "    \"hyperparameter tuning\"\n",
    "}\n",
    "\n",
    "joined_keywords = '|'.join(re.escape(kw) for kw in keywords)\n",
    "\n",
    "# number of records in this dataset\n",
    "# Visit: https://www.aminer.org/citation\n",
    "n_docs = 5_259_858\n",
    "idx = 0\n",
    "with open(\"./dblp_v14.json\", \"rb\") as f:\n",
    "    for record in tqdm(ijson.items(f, \"item\"), total=n_docs):\n",
    "        if (record[\"lang\"] != \"en\"\n",
    "            or record[\"abstract\"] == \"\"\n",
    "            or record[\"title\"] == \"\"\n",
    "            or record[\"year\"] == \"\"\n",
    "            or \"references\" not in record.keys()\n",
    "        ): continue\n",
    "\n",
    "        should_keep = False\n",
    "        record_kws = {kw.lower() for kw in record[\"keywords\"]}\n",
    "        if record_kws.intersection(keywords) or re.search(joined_keywords, record[\"title\"].lower()):\n",
    "            should_keep = True\n",
    "        elif is_xl_data:\n",
    "            # Keep every 100th paper that are not in the AI category\n",
    "            idx += 1\n",
    "            if idx % 100 == 0:\n",
    "                should_keep = True\n",
    "\n",
    "        if should_keep:\n",
    "            selected_papers.append({\n",
    "                \"id\": record[\"id\"],\n",
    "                \"title\": record[\"title\"],\n",
    "                \"doi\": record[\"doi\"],\n",
    "                \"keywords\": record[\"keywords\"],\n",
    "                \"year\": record[\"year\"],\n",
    "                \"abstract\": record[\"abstract\"]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 226234 entries, 0 to 226233\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   id        226234 non-null  object        \n",
      " 1   title     226234 non-null  object        \n",
      " 2   doi       226234 non-null  object        \n",
      " 3   keywords  226234 non-null  object        \n",
      " 4   abstract  226234 non-null  object        \n",
      " 5   date      226234 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ai_papers_data = pd.DataFrame(selected_papers)\n",
    "ai_papers_data\n",
    "\n",
    "# Convert the date to DateTime object\n",
    "ai_papers_data[\"date\"] = pd.to_datetime(ai_papers_data[\"year\"].astype(str)+\"-01-01\")\n",
    "ai_papers_data.drop(columns=[\"year\"], inplace=True)\n",
    "\n",
    "ai_papers_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>keywords</th>\n",
       "      <th>abstract</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68189</th>\n",
       "      <td>53e9aaf3b7602d9703477624</td>\n",
       "      <td>BioC: a minimalist approach to interoperabilit...</td>\n",
       "      <td>10.1093/database/bat064</td>\n",
       "      <td>[biomedical research, natural language process...</td>\n",
       "      <td>A vast amount of scientific information is enc...</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118681</th>\n",
       "      <td>53e9b80fb7602d97043c220d</td>\n",
       "      <td>Bankruptcy prediction using support vector mac...</td>\n",
       "      <td>10.1016/j.eswa.2004.12.008</td>\n",
       "      <td>[support vector machine, bankruptcy prediction...</td>\n",
       "      <td>Bankruptcy prediction has drawn a lot of resea...</td>\n",
       "      <td>2005-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101484</th>\n",
       "      <td>53e9b38fb7602d9703e7197a</td>\n",
       "      <td>Multimodal Biometrics-Based Student Attendance...</td>\n",
       "      <td>10.1109/ISM.2009.25</td>\n",
       "      <td>[face tracking, multimodal biometrics-based st...</td>\n",
       "      <td>In this paper we present a solution to obtain ...</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155002</th>\n",
       "      <td>557c560af66765fbb46afacb</td>\n",
       "      <td>Inferring social contexts from audio recording...</td>\n",
       "      <td>10.1109/MLSP.2014.6958853</td>\n",
       "      <td>[audio recording, audio signal processing, fea...</td>\n",
       "      <td>In this paper, we investigate the problem of d...</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21855</th>\n",
       "      <td>53e99e0cb7602d97026d2608</td>\n",
       "      <td>Insight of the Signal Motif of GPI-(like)-anch...</td>\n",
       "      <td></td>\n",
       "      <td>[gpi lipid modification, ptm, svm., support ve...</td>\n",
       "      <td>Many proteins contain a signal sequence at the...</td>\n",
       "      <td>2006-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>53e9999eb7602d97021e4547</td>\n",
       "      <td>A hybrid approach for indexing and retrieval o...</td>\n",
       "      <td>10.1007/978-3-642-15384-6_56</td>\n",
       "      <td>[hybrid retrieval approach, different issue, c...</td>\n",
       "      <td>This paper focuses on the problem of archaeolo...</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16434</th>\n",
       "      <td>53e99c8bb7602d970253cbd4</td>\n",
       "      <td>Fuzzy Analysis of X-Ray Images for Automated D...</td>\n",
       "      <td>10.1007/978-3-540-30133-2_64</td>\n",
       "      <td>[pattern recognition, linage segmentation, fuz...</td>\n",
       "      <td>This paper presents the design of a fuzzy deci...</td>\n",
       "      <td>2004-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175867</th>\n",
       "      <td>55c354dd683a451f09d2c43a</td>\n",
       "      <td>VHR satellite image segmentation based on topo...</td>\n",
       "      <td>10.1109/MVA.2015.7153250</td>\n",
       "      <td>[image resolution, image segmentation, learnin...</td>\n",
       "      <td>High spatial resolution satellite imagery has ...</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35948</th>\n",
       "      <td>53e9a1e1b7602d9702ae04e9</td>\n",
       "      <td>Construction of computer system for microobjec...</td>\n",
       "      <td>10.1007/978-3-540-75187-8_25</td>\n",
       "      <td>[efficient approach, formal neuron, pollen gra...</td>\n",
       "      <td>We propose a new and efficient approach for so...</td>\n",
       "      <td>2007-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29750</th>\n",
       "      <td>53e9a02db7602d9702910655</td>\n",
       "      <td>Adjusting mixture weights of gaussian mixture ...</td>\n",
       "      <td>10.1007/11430919_72</td>\n",
       "      <td>[data point, new model, gaussian model, mixtur...</td>\n",
       "      <td>Mixture models, such as Gaussian Mixture Model...</td>\n",
       "      <td>2005-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  \\\n",
       "68189   53e9aaf3b7602d9703477624   \n",
       "118681  53e9b80fb7602d97043c220d   \n",
       "101484  53e9b38fb7602d9703e7197a   \n",
       "155002  557c560af66765fbb46afacb   \n",
       "21855   53e99e0cb7602d97026d2608   \n",
       "...                          ...   \n",
       "6213    53e9999eb7602d97021e4547   \n",
       "16434   53e99c8bb7602d970253cbd4   \n",
       "175867  55c354dd683a451f09d2c43a   \n",
       "35948   53e9a1e1b7602d9702ae04e9   \n",
       "29750   53e9a02db7602d9702910655   \n",
       "\n",
       "                                                    title  \\\n",
       "68189   BioC: a minimalist approach to interoperabilit...   \n",
       "118681  Bankruptcy prediction using support vector mac...   \n",
       "101484  Multimodal Biometrics-Based Student Attendance...   \n",
       "155002  Inferring social contexts from audio recording...   \n",
       "21855   Insight of the Signal Motif of GPI-(like)-anch...   \n",
       "...                                                   ...   \n",
       "6213    A hybrid approach for indexing and retrieval o...   \n",
       "16434   Fuzzy Analysis of X-Ray Images for Automated D...   \n",
       "175867  VHR satellite image segmentation based on topo...   \n",
       "35948   Construction of computer system for microobjec...   \n",
       "29750   Adjusting mixture weights of gaussian mixture ...   \n",
       "\n",
       "                                 doi  \\\n",
       "68189        10.1093/database/bat064   \n",
       "118681    10.1016/j.eswa.2004.12.008   \n",
       "101484           10.1109/ISM.2009.25   \n",
       "155002     10.1109/MLSP.2014.6958853   \n",
       "21855                                  \n",
       "...                              ...   \n",
       "6213    10.1007/978-3-642-15384-6_56   \n",
       "16434   10.1007/978-3-540-30133-2_64   \n",
       "175867      10.1109/MVA.2015.7153250   \n",
       "35948   10.1007/978-3-540-75187-8_25   \n",
       "29750            10.1007/11430919_72   \n",
       "\n",
       "                                                 keywords  \\\n",
       "68189   [biomedical research, natural language process...   \n",
       "118681  [support vector machine, bankruptcy prediction...   \n",
       "101484  [face tracking, multimodal biometrics-based st...   \n",
       "155002  [audio recording, audio signal processing, fea...   \n",
       "21855   [gpi lipid modification, ptm, svm., support ve...   \n",
       "...                                                   ...   \n",
       "6213    [hybrid retrieval approach, different issue, c...   \n",
       "16434   [pattern recognition, linage segmentation, fuz...   \n",
       "175867  [image resolution, image segmentation, learnin...   \n",
       "35948   [efficient approach, formal neuron, pollen gra...   \n",
       "29750   [data point, new model, gaussian model, mixtur...   \n",
       "\n",
       "                                                 abstract       date  \n",
       "68189   A vast amount of scientific information is enc... 2013-01-01  \n",
       "118681  Bankruptcy prediction has drawn a lot of resea... 2005-01-01  \n",
       "101484  In this paper we present a solution to obtain ... 2009-01-01  \n",
       "155002  In this paper, we investigate the problem of d... 2014-01-01  \n",
       "21855   Many proteins contain a signal sequence at the... 2006-01-01  \n",
       "...                                                   ...        ...  \n",
       "6213    This paper focuses on the problem of archaeolo... 2010-01-01  \n",
       "16434   This paper presents the design of a fuzzy deci... 2004-01-01  \n",
       "175867  High spatial resolution satellite imagery has ... 2015-01-01  \n",
       "35948   We propose a new and efficient approach for so... 2007-01-01  \n",
       "29750   Mixture models, such as Gaussian Mixture Model... 2005-01-01  \n",
       "\n",
       "[6000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = ai_papers_data[ai_papers_data[\"date\"] >= \"2000-01-01\"].sample(6000, random_state=420)\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.to_feather(\"./aminer-subset.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narrative-trails",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
